{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning algorithms are trained using labeled data (Input where the desired output is known). <br>\n",
    "\n",
    "Usual workflow: <br>\n",
    "Data acquisition -> Data preparation -> Train/Test split -> Training -> Validation -> Deployment <br>\n",
    "\n",
    "Question: Is it fair to use single split of the data to evaluate our models performance? <br>\n",
    "NO, thats why training, validation, test set <br>\n",
    "\n",
    "New Workflow: <br>\n",
    "Data acquisition -> Data preparation -> Train/Validation/Test split -> Training on train data -> Validation on valid data (might go back from here) -> Validate on test data for final performance metric -> Deployment <br>\n",
    "\n",
    "Metrics: <br>\n",
    "Regression: Root mean squared error, Classification: Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating perfomance for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy\n",
    "- Recall\n",
    "- Precision\n",
    "- F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two states in classification:\n",
    "- Model was correct\n",
    "- Model was incorrect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Is image dog or cat? (Binary) <br>\n",
    "- We feed images to the trained model and check whether prediction was true or false\n",
    "- At the end we will have count for correct and incorrect predictions\n",
    "- Thats how we compute Accuracy\n",
    "<br>\n",
    "\n",
    "Problem: In the real world, using only this one metric wont complete the story\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "- correct predictions / total observations\n",
    "\n",
    "Good: For balanced data (same dog as cat images in dataset) <br>\n",
    "Bad: For unbalanced data (e.g. 990 oranges but only 10 apples in dataset) -> would produce 99% accuracy, but completely missclassified all apples <br><br>\n",
    "\n",
    "Thats were other metrics come in place, specifically for the apple class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision\n",
    "- Is it really a true positive?\n",
    "- **Formula**: Correct predictions / Total observations of 1 side\n",
    "- or... True Positives / True positives + False positves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall\n",
    "- Are we missing out on true positives?\n",
    "- **Formula**: Correct predictions / Total observations of 1 class\n",
    "- or... True Positives / True positives + False Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-Score\n",
    "- In cases where we want to find an optimal blend of precision and recall\n",
    "- Combining Recall and precision\n",
    "- **Formula**: 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:\n",
    "![](class_metrics.jpg)\n",
    "\n",
    "Accuracy:  7 / 10 = 70% <br>\n",
    "Precision: 3 / 5 = 60% for Apples (Just focus on the apple **si**de for apple preci**si**on and vice versa) <br> \n",
    "Recall: 3 / 4 = 75% for Apples (To calculate rec**all**, focus on **all** apples) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision / Recall tradeoff**: Change decision threshold towards precision or towards recall <br>\n",
    "-> Use F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "\n",
    "- a true positive would be someone having the disease and model it correctly\n",
    "- a true negative would be someone not having the disease and model it correctly\n",
    "- a false positive would be someone not having the disease and model predict that they do have it\n",
    "- a false negative would be someone having the disease and model predict that they not have it\n",
    "  \n",
    "![](confusion_matrix.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating perfomance for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression: Trying to predict continuous values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mean Absolute Error\n",
    "- Mean Squared Error\n",
    "- Root Mean Square Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error (simplest)\n",
    "- This is the mean of the absolute value of errors (no negative, abs)\n",
    "- **Formula**: abs(True price - predicted price) / all predictions\n",
    "- Problem: it wont punish large errors. We want the error to make account for outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error\n",
    "- This is the mean of the squared errors\n",
    "- Larger errors are noted more than with MAE, making MSE more popular\n",
    "- **Formula**: (True price - predicted price)**2 / all predictions\n",
    "- Problem: That squaring also squares the units themselves. Meaning the house price prediction is in dollars, now we getting house price in dollars**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean Squared Error (most popular)\n",
    "- to fix this we use Root Mean Square Error\n",
    "- Just the root of the MSE\n",
    "- **Formula**: root((True price - predicted price)**2 / all predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is RMSE of 10â‚¬ good?\n",
    "- depends on context\n",
    "- good: for house price prediction\n",
    "- bad: for candy bar prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3dd02a6aea8937326c57b039eb9536dc82a9b6b540bd6b363cd3d70915ded733"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('data_science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
