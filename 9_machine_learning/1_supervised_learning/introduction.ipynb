{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning algorithms are trained using labeled data (Input where the desired output is known). <br>\n",
    "\n",
    "Usual workflow: <br>\n",
    "Data acquisition -> Data preparation -> Train/Test split -> Training -> Validation -> Deployment <br>\n",
    "\n",
    "Question: Is it fair to use single split of the data to evaluate our models performance? <br>\n",
    "NO, thats why training, validation, test set <br>\n",
    "\n",
    "New Workflow: <br>\n",
    "Data acquisition -> Data preparation -> Train/Validation/Test split -> Training on train data -> Validation on valid data (might go back from here) -> Validate on test data for final performance metric -> Deployment <br>\n",
    "\n",
    "Metrics: <br>\n",
    "Regression: Root mean squared error, Classification: Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating perfomance for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy\n",
    "- Recall\n",
    "- Precision\n",
    "- F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two states in classification:\n",
    "- Model was correct\n",
    "- Model was incorrect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Is image dog or cat? (Binary) <br>\n",
    "- We feed images to the trained model and check whether prediction was true or false\n",
    "- At the end we will have count for correct and incorrect predictions\n",
    "- Thats how we compute Accuracy\n",
    "<br>\n",
    "\n",
    "Problem: In the real world, using only this one metric wont complete the story\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "- is the number of correct predictions divided by total number of predictions\n",
    "\n",
    "Good: For balanced data (same dog as cat images in dataset) <br>\n",
    "Bad: For unbalanced data (cant proberly train for cat for example) <br><br>\n",
    "\n",
    "Thats were other metrics come in place..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall\n",
    "- Ability of the model to find all relevant cases within a dataset\n",
    "- **Formula**: Number of true positives / (number of true positives + number of false negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision\n",
    "- Ability of a classification model to identify only the relevant data points\n",
    "- **Formula**: Number of true positives / (number of true positives + number of false positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-Score\n",
    "- In cases where we want to find an optimal blend of precision and recall\n",
    "- Combining Recall and precision\n",
    "- **Formula**: 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "\n",
    "- a true positive would be someone having the disease and model it correctly\n",
    "- a true negative would be someone not having the disease and model it correctly\n",
    "- a false positive would be someone not having the disease and model predict that they do have it\n",
    "- a false negative would be someone having the disease and model predict that they not have it\n",
    "  \n",
    "![](confusion_matrix.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating perfomance for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression: Trying to predict continuous values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mean Absolute Error\n",
    "- Mean Squared Error\n",
    "- Root Mean Square Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error (simplest)\n",
    "- This is the mean of the absolute value of errors (no negative, abs)\n",
    "- **Formula**: abs(True price - predicted price) / all predictions\n",
    "- Problem: it wont punish large errors. We want the error to make account for outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error\n",
    "- This is the mean of the squared errors\n",
    "- Larger errors are noted more than with MAE, making MSE more popular\n",
    "- **Formula**: (True price - predicted price)**2 / all predictions\n",
    "- Problem: That squaring also squares the units themselves. Meaning the house price prediction is in dollars, now we getting house price in dollars**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean Squared Error (most popular)\n",
    "- to fix this we use Root Mean Square Error\n",
    "- Just the root of the MSE\n",
    "- **Formula**: root((True price - predicted price)**2 / all predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is RMSE of 10â‚¬ good?\n",
    "- depends on context\n",
    "- good: for house price prediction\n",
    "- bad: for candy bar prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
