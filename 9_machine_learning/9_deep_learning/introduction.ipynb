{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- inputs: x\n",
    "- weight: w\n",
    "- bias: b\n",
    "-> x*w + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- w implies how much weight to give the input\n",
    "- b can be seen as an offset, making w*b have to reach a certain threshold before having an effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: <br>\n",
    "b = -10 means the product x*w have to overcome 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, set boundaries for the overall output of x*w + b <br>\n",
    "z = x*w + b <br>\n",
    "Then pass z to an activation function to limit its value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](dl_1.jpg)\n",
    "![](dl_2.jpg)\n",
    "![](dl_3.jpg)\n",
    "![](dl_4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... where output layer has multiple neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-Exclusive Classes: <br>\n",
    "- A data point can have multiple classes\n",
    "- e.g. photos with multiple tags (beach, family, vacations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mutually-Exclusive Classes: <br>\n",
    "-  A data point can only have one class\n",
    "- e.g. Photos can be categorized as being greyscale (black/white) or full color. It can not be both\n",
    "\n",
    "![](dl_5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot-encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](dl_7.jpg)\n",
    "![](dl_6.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply e.g. Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](dl_8.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But what we do with Mutually Exclusive Classes (only one class assigned to data point)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Softmax\n",
    "\n",
    "![](dl_9.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How the Network learns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Only important in training phase with training data, NOT when testing with test data\n",
    "- Compare predictions with ground truth\n",
    "- y = ground truth\n",
    "- a = neurons prediction\n",
    "- - w*x + b = z\n",
    "- sigmoid(Z) = a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Quadratic cost function\n",
    "- Calculate the difference between real values y(x) against predictions a(x)\n",
    "\n",
    "![](dl_10.jpg)\n",
    "![](dl_11.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- how to calculate w that leads us to the lowest cost?\n",
    "\n",
    "![](dl_12.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking Derivative? No because in reality the network is of n-dimensional:\n",
    "\n",
    "![](dl_13.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thats why use Gradient Descent\n",
    "- calculate slope at random point\n",
    "- move down direction of the slope\n",
    "- repeat until reached zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](dl_14.jpg)\n",
    "![](dl_15.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate\n",
    "\n",
    "Small step size = Takes longer to find minimum. <br>\n",
    "Large step size = risk to overshoot minimum <br>\n",
    "steps size = **learning rate**\n",
    "\n",
    "![](dl_16.jpg)\n",
    "![](dl_17.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Gradient Descent\n",
    "- we can also adapt learning rate as we descent\n",
    "- start with larg learning rate and go smaller and smaller\n",
    "\n",
    "**-> Adam optimizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: For classification, we use the cross entropy loss instead of quadratic cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- backpropagating the error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow vs Keras\n",
    "- TF is an open source DL library by google\n",
    "- Keras is a DL library that can use other DL libraries underneath like TF etc.\n",
    "- TF used to be to complex, thats why people used Keras as it was easier to use DL API\n",
    "- Keras is now officialy part of TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
